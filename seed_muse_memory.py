# seed_muse_memory.py
"""
Seed MUSE memory with initial strategic lessons and tool hints.

This script pre-populates MUSE memory with common best practices
to help the agent avoid common mistakes from the start.
"""

import json
from pathlib import Path
from datetime import datetime


def seed_strategic_memory(memory_path: Path):
    """Seed strategic memory with common lessons."""
    
    lessons = [
        {
            "lesson": "–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π L3 –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º internet_search - –≤–æ–∑–º–æ–∂–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É–∂–µ –µ—Å—Ç—å",
            "context": {"tool_name": "internet_search"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.8
        },
        {
            "lesson": "–ü–æ—Å–ª–µ web_fetch –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π web_search_in_page –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö - web_fetch –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ HTML",
            "context": {"tool_name": "web_fetch"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.9
        },
        {
            "lesson": "–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π web_fetch –Ω–∞ —Ç–æ–º –∂–µ URL - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–π web_search_in_page",
            "context": {"tool_name": "web_fetch"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.9
        },
        {
            "lesson": "–ü—Ä–∏ –æ—à–∏–±–∫–µ 'file not found' —Å–Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–π list_directory —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã",
            "context": {"tool_name": "read_file", "error_type": "not_found"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.8
        },
        {
            "lesson": "–ò—Å–ø–æ–ª—å–∑—É–π –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤ –∫–æ–≥–¥–∞ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ - —ç—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫–∏",
            "context": {"tool_name": "read_file"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.7
        },
        {
            "lesson": "–ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –°–†–ê–ó–£ —Å–æ—Ö—Ä–∞–Ω–∏ –µ—ë –≤ —Ñ–∞–π–ª - –Ω–µ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–π –Ω–∞ –ø–æ—Ç–æ–º",
            "context": {"tool_name": "create_file"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.8
        },
        {
            "lesson": "–ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ —Ç—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞, –∏—Å–ø–æ–ª—å–∑—É–π analyze_code –ø–æ—Å–ª–µ read_file - –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–π —ç—Ç–æ—Ç —à–∞–≥",
            "context": {"tool_name": "analyze_code"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.7
        },
        {
            "lesson": "–ü—Ä–∏ timeout –æ—à–∏–±–∫–µ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫",
            "context": {"error_type": "timeout"},
            "created": datetime.now().isoformat(),
            "last_seen": datetime.now().isoformat(),
            "usage_count": 1,
            "quality_score": 0.6
        }
    ]
    
    data = {
        "lessons": lessons,
        "last_updated": datetime.now().isoformat()
    }
    
    memory_path.parent.mkdir(parents=True, exist_ok=True)
    with open(memory_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Seeded {len(lessons)} strategic lessons to {memory_path}")


def seed_procedural_memory(memory_path: Path):
    """Seed procedural memory with common SOPs."""
    
    sops = [
        {
            "task_description": "–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª",
            "steps": [
                "internet_search(query='–∑–∞–ø—Ä–æ—Å')",
                "web_fetch(url='–Ω–∞–π–¥–µ–Ω–Ω—ã–π_url')",
                "web_search_in_page(url='—Ç–æ—Ç_–∂–µ_url', query='—á—Ç–æ_–∏—â–µ–º')",
                "create_file(file_path='result.txt', content='–Ω–∞–π–¥–µ–Ω–Ω–∞—è_–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è')",
                "finish(final_answer='–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞')"
            ],
            "created": datetime.now().isoformat(),
            "last_used": datetime.now().isoformat(),
            "usage_count": 1,
            "success_count": 1,
            "quality_score": 0.9
        },
        {
            "task_description": "–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —Ñ–∞–π–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            "steps": [
                "list_directory(directory_path='.')",
                "read_file(file_path='—Ñ–∞–π–ª.py')",
                "analyze_code(code='–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–π_–∫–æ–¥', language='python')",
                "create_file(file_path='analysis.txt', content='—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã_–∞–Ω–∞–ª–∏–∑–∞')",
                "finish(final_answer='–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω')"
            ],
            "created": datetime.now().isoformat(),
            "last_used": datetime.now().isoformat(),
            "usage_count": 1,
            "success_count": 1,
            "quality_score": 0.8
        },
        {
            "task_description": "–ß—Ç–µ–Ω–∏–µ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞",
            "steps": [
                "read_file(file_path='—Ñ–∞–π–ª.txt')",
                "replace_in_file(file_path='—Ñ–∞–π–ª.txt', old_text='—Å—Ç–∞—Ä—ã–π_—Ç–µ–∫—Å—Ç', new_text='–Ω–æ–≤—ã–π_—Ç–µ–∫—Å—Ç')",
                "read_file(file_path='—Ñ–∞–π–ª.txt')",
                "finish(final_answer='—Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω')"
            ],
            "created": datetime.now().isoformat(),
            "last_used": datetime.now().isoformat(),
            "usage_count": 1,
            "success_count": 1,
            "quality_score": 0.8
        }
    ]
    
    data = {
        "sops": sops,
        "last_updated": datetime.now().isoformat()
    }
    
    memory_path.parent.mkdir(parents=True, exist_ok=True)
    with open(memory_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Seeded {len(sops)} procedural SOPs to {memory_path}")


def seed_tool_memory(memory_path: Path):
    """Seed tool memory with common hints."""
    
    tool_hints = {
        "internet_search": [
            {
                "hint": "–ü—Ä–æ–≤–µ—Ä—å L3 –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —É–∂–µ —Ç–∞–º",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.8
            },
            {
                "hint": "–§–æ—Ä–º—É–ª–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ - –∏–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Å–ª–æ–≤",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.7
            }
        ],
        "web_fetch": [
            {
                "hint": "–ü–æ—Å–ª–µ web_fetch –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π web_search_in_page –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.9
            },
            {
                "hint": "–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π web_fetch –Ω–∞ —Ç–æ–º –∂–µ URL - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É–∂–µ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.9
            }
        ],
        "web_search_in_page": [
            {
                "hint": "–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ HTML",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.7
            }
        ],
        "read_file": [
            {
                "hint": "–ü—Ä–∏ –æ—à–∏–±–∫–µ 'not found' –∏—Å–ø–æ–ª—å–∑—É–π list_directory —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.8
            },
            {
                "hint": "–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.6
            }
        ],
        "create_file": [
            {
                "hint": "–°–æ—Ö—Ä–∞–Ω—è–π –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å—Ä–∞–∑—É - –Ω–µ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–π –Ω–∞ –ø–æ—Ç–æ–º",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.8
            }
        ],
        "analyze_code": [
            {
                "hint": "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –µ—Å–ª–∏ –∑–∞–¥–∞—á–∞ —Ç—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞",
                "context": {},
                "created": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
                "usage_count": 1,
                "effectiveness": 0.7
            }
        ]
    }
    
    data = {
        "tool_hints": tool_hints,
        "last_updated": datetime.now().isoformat()
    }
    
    memory_path.parent.mkdir(parents=True, exist_ok=True)
    with open(memory_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    total_hints = sum(len(hints) for hints in tool_hints.values())
    print(f"‚úÖ Seeded {total_hints} tool hints for {len(tool_hints)} tools to {memory_path}")


def main():
    """Seed all MUSE memory components."""
    
    base_path = Path(__file__).parent / "memory" / "muse"
    
    print("üå± Seeding MUSE memory with initial knowledge...")
    
    seed_strategic_memory(base_path / "strategic.json")
    seed_procedural_memory(base_path / "procedural.json")
    seed_tool_memory(base_path / "tool_memory.json")
    
    print("\n‚úÖ MUSE memory seeding complete!")
    print(f"üìÅ Memory location: {base_path}")
    print("\nüí° The agent will now start with these pre-seeded learnings.")


if __name__ == "__main__":
    main()
