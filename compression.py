# compression.py
"""
–ú–æ–¥—É–ª—å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–∂–∞—Ç–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è ReAct-–∞–≥–µ–Ω—Ç–∞.

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- compress_history_smart(): –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏
- compress_block_on_overflow(): –°–∂–∞—Ç–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏
- _summarize_observation(): –°–∂–∞—Ç–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö Observation —á–µ—Ä–µ–∑ LLM
- _extract_key_facts(): –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ (URL, —Ñ–∞–π–ª—ã, –≤–µ—Ä—Å–∏–∏)
- _compress_images(): –°–∂–∞—Ç–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
"""

import re
import logging
from typing import List, Dict

logger = logging.getLogger(__name__)


def compress_block_on_overflow(
    block_content: str,
    llm,
    max_tokens: int = 2048,
    preserve_images: bool = True
) -> str:
    """
    –°–∂–∏–º–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±–ª–æ–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤.
    –í–º–µ—Å—Ç–æ –¥—Ä–æ–ø–∞ –≤—Å–µ–π —Å–µ—Å—Å–∏–∏ —Å–∂–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–ø–æ–ª–Ω—è—é—â–∏–π –±–ª–æ–∫.
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    1. –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º/—É–¥–∞–ª—è–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ
    2. –ï—Å–ª–∏ –µ—Å—Ç—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - —Å–∂–∏–º–∞–µ–º —á–µ—Ä–µ–∑ LLM
    3. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã
    
    Args:
        block_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞ –¥–ª—è —Å–∂–∞—Ç–∏—è
        llm: –≠–∫–∑–µ–º–ø–ª—è—Ä LLM –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±–ª–æ–∫–∞
        preserve_images: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ False - —É–¥–∞–ª—è—é—Ç—Å—è)
        
    Returns:
        –°–∂–∞—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
    """
    logger.info(f"üóúÔ∏è –°–∂–∞—Ç–∏–µ –ø–µ—Ä–µ–ø–æ–ª–Ω—è—é—â–µ–≥–æ –±–ª–æ–∫–∞ (limit={max_tokens} —Ç–æ–∫–µ–Ω–æ–≤)...")
    
    original_length = len(block_content)
    
    # === –®–ê–ì 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ===
    image_pattern = r'\[(?:PAGE_\d+_)?IMAGE_DATA:[^\]]+\]'
    images = re.findall(image_pattern, block_content)
    
    if images:
        logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –±–ª–æ–∫–µ: {len(images)}")
        
        if preserve_images and len(images) <= 3:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            text_without_images = re.sub(image_pattern, '', block_content)
            compressed_images = images[:3]
        else:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º 1 –µ—Å–ª–∏ preserve_images
            text_without_images = re.sub(image_pattern, '', block_content)
            compressed_images = images[:1] if preserve_images else []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if len(images) > len(compressed_images):
            removed_count = len(images) - len(compressed_images)
            text_without_images += f"\n[–£–¥–∞–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤: {removed_count}]"
    else:
        text_without_images = block_content
        compressed_images = []
    
    # === –®–ê–ì 2: –°–∂–∞—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –æ–Ω –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ===
    if len(text_without_images) > max_tokens * 4:  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
        logger.debug(f"–°–∂–∏–º–∞–µ–º —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ LLM...")
        
        # –°–∂–∏–º–∞–µ–º —á–µ—Ä–µ–∑ LLM
        compressed_text = _summarize_observation(text_without_images, llm)
    else:
        # –¢–µ–∫—Å—Ç —É–∂–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É
        compressed_text = text_without_images
    
    # === –®–ê–ì 3: –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ===
    result_parts = [compressed_text]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º)
    if compressed_images:
        result_parts.extend(compressed_images)
    
    result = "\n".join(result_parts)
    
    compression_ratio = (1 - len(result) / original_length) * 100 if original_length > 0 else 0
    logger.info(f"‚úÖ –ë–ª–æ–∫ —Å–∂–∞—Ç: {original_length} ‚Üí {len(result)} —Å–∏–º–≤–æ–ª–æ–≤ ({compression_ratio:.1f}% —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ)")
    
    return result


def _compress_images_in_message(content: str, max_images: int = 2) -> str:
    """
    –°–∂–∏–º–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏.
    
    Args:
        content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        max_images: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
    Returns:
        –°–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    image_pattern = r'\[(?:PAGE_\d+_)?IMAGE_DATA:[^\]]+\]'
    images = re.findall(image_pattern, content)
    
    if len(images) <= max_images:
        return content
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text_without_images = re.sub(image_pattern, '', content)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ max_images
    kept_images = images[:max_images]
    removed_count = len(images) - max_images
    
    result = text_without_images
    if kept_images:
        result += "\n" + "\n".join(kept_images)
    
    result += f"\n[–£–¥–∞–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {removed_count}]"
    
    logger.debug(f"–°–∂–∞—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)} ‚Üí {max_images}")
    
    return result


def compress_history_smart(
    history: List[Dict],
    scratchpad: Dict,
    llm,
    memory_manager,
    current_chat: str
) -> List[Dict]:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –±–µ–∑ –∑–∞—Å–∏—Ä–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏.
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    1. –°–∂–∏–º–∞–µ–º –¢–û–õ–¨–ö–û –¥–ª–∏–Ω–Ω—ã–µ Observation (>1500 —Å–∏–º–≤–æ–ª–æ–≤) —á–µ—Ä–µ–∑ LLM
    2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ L3 –ø–∞–º—è—Ç—å –¢–û–õ–¨–ö–û –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã (URL, —Ñ–∞–π–ª—ã, –≤–µ—Ä—Å–∏–∏)
    3. –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—ã –∏ –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞
    
    Args:
        history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        scratchpad: –†–∞–±–æ—á–∞—è –ø–∞–º—è—Ç—å (–ø–ª–∞–Ω, —Ü–µ–ª—å)
        llm: –≠–∫–∑–µ–º–ø–ª—è—Ä LLM –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        memory_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏
        current_chat: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞
        
    Returns:
        –°–∂–∞—Ç–∞—è –∏—Å—Ç–æ—Ä–∏—è
    """
    logger.info("üóúÔ∏è –ù–∞—á–∞–ª–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏...")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    original_count = len(history)
    observations_compressed = 0
    facts_saved = 0
    duplicates_removed = 0
    
    # === –®–ê–ì 1: –°–∂–∞—Ç–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö Observation —á–µ—Ä–µ–∑ LLM ===
    compressed_history = []
    
    # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º (—Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç)
    if history:
        compressed_history.append(history[0])
    
    for i, msg in enumerate(history[1:], 1):
        content = msg.get('content', '')
        
        # –°–∂–∏–º–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –µ—Å–ª–∏ –∏—Ö –±–æ–ª—å—à–µ 2
        image_pattern = r'\[(?:PAGE_\d+_)?IMAGE_DATA:[^\]]+\]'
        images = re.findall(image_pattern, content)
        
        if len(images) > 2:
            content = _compress_images_in_message(content, max_images=2)
            logger.debug(f"–°–∂–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ #{i}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ Observation
        if content.startswith('Observation:') and len(content) > 1500:
            logger.debug(f"–°–∂–∏–º–∞–µ–º Observation #{i} (–¥–ª–∏–Ω–∞: {len(content)})")
            
            # –°–∂–∏–º–∞–µ–º —á–µ—Ä–µ–∑ LLM
            summary = _summarize_observation(content, llm)
            
            compressed_history.append({
                "role": msg['role'],
                "content": f"Observation (—Å–∂–∞—Ç–æ): {summary}"
            })
            observations_compressed += 1
            
        else:
            # –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–Ω–æ —Å —É–∂–µ —Å–∂–∞—Ç—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏)
            compressed_history.append({
                "role": msg['role'],
                "content": content
            })
    
    logger.info(f"üóúÔ∏è –°–∂–∞—Ç–æ –¥–ª–∏–Ω–Ω—ã—Ö Observation: {observations_compressed}")
    
    # === –®–ê–ì 2: –£–î–ê–õ–ï–ù–û –¥—É–±–ª–∏—Ä—É—é—â–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å ===
    # –§–∞–∫—Ç—ã —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (agent.py lines 458-476)
    # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞–º—è—Ç–∏
    
    # === –®–ê–ì 3: –£–¥–∞–ª–µ–Ω–∏–µ –º—É—Å–æ—Ä–∞ (–ø–æ–≤—Ç–æ—Ä—ã, –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞) ===
    cleaned_history = []
    seen_hashes = set()
    
    for msg in compressed_history:
        content = msg.get('content', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ (—É–∂–µ –Ω–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã)
        if any(keyword in content for keyword in [
            '–û–®–ò–ë–ö–ê –§–û–†–ú–ê–¢–ê',
            '–ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É',
            '–¢–†–ï–ë–£–ï–ú–´–ô –§–û–†–ú–ê–¢:',
            '–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –§–û–†–ú–ê–¢–ê'
        ]):
            duplicates_removed += 1
            logger.debug("üßπ –£–¥–∞–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞")
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ Observation
        if content.strip() in ['Observation:', 'Observation: ']:
            duplicates_removed += 1
            logger.debug("üßπ –£–¥–∞–ª—ë–Ω –ø—É—Å—Ç–æ–π Observation")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ –ø–µ—Ä–≤—ã–º 200 —Å–∏–º–≤–æ–ª–∞–º)
        content_hash = content[:200]
        if content_hash in seen_hashes:
            duplicates_removed += 1
            logger.debug("üßπ –£–¥–∞–ª—ë–Ω –¥—É–±–ª–∏–∫–∞—Ç")
            continue
        
        seen_hashes.add(content_hash)
        cleaned_history.append(msg)
    
    logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –º—É—Å–æ—Ä–∞: {duplicates_removed}")
    
    # === –§–ò–ù–ê–õ: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ===
    final_count = len(cleaned_history)
    reduction = ((original_count - final_count) / original_count * 100) if original_count > 0 else 0
    
    logger.info(f"‚úÖ –°–∂–∞—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {original_count} ‚Üí {final_count} —Å–æ–æ–±—â–µ–Ω–∏–π ({reduction:.1f}% —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ)")
    logger.info(f"üìä –ò—Ç–æ–≥–æ: {observations_compressed} —Å–∂–∞—Ç–æ, {facts_saved} —Ñ–∞–∫—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ, {duplicates_removed} —É–¥–∞–ª–µ–Ω–æ")
    
    return cleaned_history


def _summarize_observation(observation_text: str, llm) -> str:
    """
    –°–∂–∏–º–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π Observation —á–µ—Ä–µ–∑ LLM –¥–æ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
    
    Args:
        observation_text: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç Observation
        llm: –≠–∫–∑–µ–º–ø–ª—è—Ä LLM
        
    Returns:
        –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
    """
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 3000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
    truncated_text = observation_text[:3000]
    
    prompt = f"""–°–æ–∂–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –¢–û–õ–¨–ö–û –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã.

–ü–û–õ–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:
{truncated_text}

–ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):"""
    
    try:
        messages = [{"role": "user", "content": prompt}]
        output = llm.create_chat_completion(
            messages=messages,
            max_tokens=256,  # –ö–æ—Ä–æ—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
            temperature=0.2   # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ = —Ç–æ—á–Ω–æ—Å—Ç—å
        )
        
        summary = output['choices'][0]['message']['content'].strip()
        logger.debug(f"üìù –†–µ–∑—é–º–µ —Å–æ–∑–¥–∞–Ω–æ: {len(observation_text)} ‚Üí {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return summary
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        # Fallback: –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∞—è –æ–±—Ä–µ–∑–∫–∞
        return observation_text[:500] + "... (–æ–±—Ä–µ–∑–∞–Ω–æ)"


def _extract_key_facts(observation_text: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¢–û–õ–¨–ö–û –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ Observation.
    
    –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã:
    - URL (–Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å http:// –∏–ª–∏ https://)
    - –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ (—Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è .py, .txt, .md, –∏ —Ç.–¥.)
    - –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤–µ—Ä—Å–∏–∏, –¥–∞—Ç—ã)
    - –£–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π (Python, Node.js, –∏ —Ç.–¥.)
    
    Args:
        observation_text: –¢–µ–∫—Å—Ç Observation
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏ –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    facts = []
    
    # === 1. –ò–∑–≤–ª–µ–∫–∞–µ–º URL ===
    urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', observation_text)
    if urls:
        # –ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º 3 URL, —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_urls = list(dict.fromkeys(urls[:3]))
        facts.append(f"URL: {', '.join(unique_urls)}")
    
    # === 2. –ò–∑–≤–ª–µ–∫–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ ===
    files = re.findall(
        r'\b[\w-]+\.(py|txt|md|json|yaml|yml|toml|cfg|ini|sh|bash|js|ts|html|css|sql)\b',
        observation_text,
        re.IGNORECASE
    )
    if files:
        # –ú–∞–∫—Å–∏–º—É–º 3 —Ñ–∞–π–ª–∞, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
        unique_files = list(dict.fromkeys(files[:3]))
        facts.append(f"–§–∞–π–ª—ã: {', '.join(unique_files)}")
    
    # === 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏–∏ ===
    # –ü–∞—Ç—Ç–µ—Ä–Ω: Python 3.13, version 2.1.0, v3.0, –∏ —Ç.–¥.
    versions = re.findall(
        r'\b(?:Python|Node|v\.?|version|ver\.?)\s*(\d+\.\d+(?:\.\d+)?)\b',
        observation_text,
        re.IGNORECASE
    )
    if versions:
        unique_versions = list(dict.fromkeys(versions[:2]))
        facts.append(f"–í–µ—Ä—Å–∏–∏: {', '.join(unique_versions)}")
    
    # === 4. –ò–∑–≤–ª–µ–∫–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π ===
    technologies = re.findall(
        r'\b(Python|JavaScript|TypeScript|Node\.js|React|Vue|Angular|Django|Flask|FastAPI|Docker|Kubernetes|PostgreSQL|MySQL|MongoDB|Redis)\b',
        observation_text,
        re.IGNORECASE
    )
    if technologies:
        unique_tech = list(dict.fromkeys([t.lower() for t in technologies[:3]]))
        facts.append(f"–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {', '.join(unique_tech)}")
    
    # === 5. –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—ã ===
    dates = re.findall(
        r'\b(\d{4}-\d{2}-\d{2}|\d{2}\.\d{2}\.\d{4}|\d{1,2}\s+(?:—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+\d{4})\b',
        observation_text,
        re.IGNORECASE
    )
    if dates:
        facts.append(f"–î–∞—Ç—ã: {', '.join(dates[:2])}")
    
    # === 6. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ - –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 150 —Å–∏–º–≤–æ–ª–æ–≤ ===
    if not facts:
        # –£–±–∏—Ä–∞–µ–º "Observation: " –µ—Å–ª–∏ –µ—Å—Ç—å
        clean_text = observation_text.replace('Observation:', '').strip()
        return clean_text[:150].strip()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∞–∫—Ç—ã
    result = " | ".join(facts)
    
    logger.debug(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {result[:100]}...")
    
    return result
